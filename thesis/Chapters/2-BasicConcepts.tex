\chapter{Conceptos básicos}
\label{BasicConcepts}

\section{Redes neuronales}
Las redes neuronales son modelos computacionales basados en las conexiones
neuronales que ocurren dentro del cerebro. Están compuestas de neuronas
artificiales (también llamadas nodos o unidades) conectadas a través de
conexiones dirigidas. Cada conexión tiene un peso numérico que determina la
fuerza de la conexión.

Las neuronas artificiales, al igual que las biológicas, se activan cuando
reciben un determinado estímulo. Para determinar si una neurona artificial se
activa primero hace la suma de sus entradas ponderadas con los pesos de las
conexiones y luego aplica una función de activación para producir la salida.

Existen dos categorías principales de estructuras de redes neuronales:
\textbf{redes con alimentación-hacia-delante} o \textbf{redes recurrentes},
dependiendo de si el grafo que representa las conexiones de la red es acíclico
o cíclico.

En este trabajo se van a usar redes con alimentación-hacia-delante. Este tipo
de redes representa una función de sus estados actuales, por lo que no tiene
otro estado interno que no sea el de sus propios pesos. Están organizadas en
capas de forma que cada neurona recibe entradas únicamente de las neuronas de
la capa que la precede. En la figura \ref{red_neuronal} se puede apreciar una
red neuronal con dos entradas, una capa oculta (que no tiene neuronas de
entrada ni de salida) con dos neuronas y una salida, así como los pesos para
cada conexión.

\begin{figure}
    \centering
    \caption{\textit{Representación de una red neuronal con dos entradas, una
    capa oculta con dos neuronas y una salida.}}
  \label{red_neuronal}
  \includegraphics[width=.7\textwidth]{red_neuronal}
\end{figure}

La idea de las redes neuronales es que sean capaces de aprender funciones
generalizando ejemplos de entradas y salidas de la función. Un algoritmo de
aprendizaje para redes neuronales deberá ajustar los pesos de la red de tal
manera que se minimice alguna medida del error producido sobre el conjunto de
entrenamiento \parencite{russel_norvig}.


\subsection{Propagación hacia atrás}

El algoritmo usado para entrenar la red se llama propagación hacia atrás. Se
trata de actualizar los pesos de la red para reducir el error, entendido como
la diferencia entre la salida de la red con la salida esperada.

Para actualizar los pesos se usa el descenso del gradiente. Cada peso que lleva
a una neurona de salida se actualiza de la siguiente manera: 
\[
    W_j \leftarrow W_j + \alpha \times Err \times g'(in) \times x_j
\]

Siendo $W_j$ el peso, $\alpha$ la tasa de aprendizaje, $Err$ el error cometido
en la salida, $g'$ la derivada parcial de la función de activación y $x_j$ la
entrada. Si el error es positivo, la salida de la red es demasiado pequeña y por
ello los pesos se incrementan para las entradas positivas y se decrementan para
las entradas negativas. Cuando el error el negativo ocurre lo contrario.

Para actualizar los pesos de las neuronas ocultas se define una función de
actualización de pesos. Es la misma con la que se actualizan los pesos de la
capa final pero ahora se entiende que cada nodo oculto es responsable de una
fracción del error en cada nodo de salida, proporcional al peso que tenga la
conexión entre ambos nodos. Así que los valores se propagan hacia atrás con la
fuerza de la conexión entre el nodo de salida y el nodo oculto.

\subsection{Codificación \textit{onehot}}

La codificación \textit{onehot} es la representación de variables categóricas
como un vector binario. Cada elemento del vector representa la pertenencia a
una de las categorías disponibles en el problema. El vector final tendrá el
mismo tamaño que la cantidad de categorías y estará completo de ceros, excepto
en el lugar perteneciente a la categoría del elemento, donde contendrá un uno.

Esta codificación es útil para redes neuronales, ya que al trabajar con varias
categorías es más eficiente tener una neurona de salida para cada categoría
disponible, en vez de trabajar con combinaciones de menos neuronas.


\section{Imágenes digitales}

Una imagen en el ámbito digital se entiende como una matriz de puntos.
Cada uno de estos puntos puede ser interpretado como un número real entre 0 y 1, que representa la localización de este punto en la escala de grises. En esta representación usaremos valores menores para los puntos más oscuros y valores mayores para puntos más claros.

Un ejemplo de esa representación es la matriz de la figura \ref{Seven_number}, que representa la imagen de la figura \ref{Seven_corner}.

\begin{figure}
    \centering
    \caption{\textit{Imagen parcial en blanco y negro de un dígito escrito a mano}}
  \label{Seven_corner}
  \includegraphics[width=.6\textwidth]{Seven_corner}
\end{figure}

\begin{figure}
    \centering
    \caption{\textit{Matriz que representa los valores de cada punto en la imágen de la figura \ref{Seven_corner}}}
  \label{Seven_number}
  \includegraphics[width=\textwidth]{Seven_number}
\end{figure}


En imágenes en color se suele usar el sistema \textit{RGB (Red, Green, Blue)} para representar diferentes colores en cada punto de la imagen. En vez de usar un solo valor por punto se usan tres valores, cada uno representando la intensidad del color rojo, verde y azul en ese punto. Superponiendo estos tres valores se consigue el color final. Por lo tanto, las imágenes \textit{RGB} constan de tres matrices, cada una con los valores reales entre 0 y 1 para cada color.

Para simplificar, algunos ejemplos de esta memoria van a usar una escala de grises, pero son aplicables a imágenes en color aplicando las operaciones a las tres diferentes matrices al mismo tiempo.

\section{Filtros convolucionales}

Al trabajar con esta interpretación de lo que es una imagen, se pueden usar operaciones sobre la matriz de la imagen para transformarla de diferentes maneras.

Consideremos por ejemplo la siguiente matriz 3$\times$3 (llamada matriz filtro de convolución):

\[
  F=
  \left[ {\begin{array}{ccc}
   -1 & -1 & -1 \\
   1 & 1 & 1 \\
   0 & 0 & 0 \\
  \end{array} } \right]
\]

Se puede usar $F$ como un filtro para una imagen de la siguiente manera: primero, superponemos la matriz en algún punto de la imagen. Esto modificará el pixel donde ha quedado colocado el valor central de la matriz F. Para ello multiplicamos cada uno de los valores superpuestos, sumamos los resultados y los sustituimos en el valor central. Esto se hace para cada píxel de la imagen original (superponer el filtro en ese píxel y sustituir el valor por la operación).

En los bordes de la matriz existen menos píxeles adyacentes a cada píxel: seis en los bordes y tres en las esquinas. Para que la operación se haga con la misma cantidad de elementos se presupone que todos los valores que no existen son 0.

En el caso de la matriz F, la fila superior son todos valores negativos, la intermedia son todos 1 y la inferior todos ceros. Si aplicamos entonces la operación descrita sobre una imagen, los píxeles más brillantes (aquellos con mayor valor) en la imagen resultante serán los que su fila superior es cero, eliminando los valores negativos y su fila intermedia es 1. 

Esto ocurrirá con más frecuencia en los bordes superiores de objetos claros con fondo oscuro.

Para mostar la utilidad de los filtros, los aplicaremos a la imagen de un dígito escrito a mano, sacado de la base de datos MNIST \parencite{lecun-mnisthandwrittendigit-2010}, que incluye 70000 imágenes de dígitos alfanuméricos escritos a mano.

\begin{figure}
    \centering
    \caption{Imágen de un dígito escrito a mano, sacado de la base de datos MNIST}
  \label{seven}
  \includegraphics{seven}
\end{figure}

Si aplicamos el filtro F a la imagen de la figura \ref{seven} podemos observar cómo resalta en blanco los bordes superiores y en negro los inferiores. Véase la primera columna de la figura \ref{filters}. Filtros similares, rotando los valores del filtro F, son capaces de resaltar bordes laterales u oblicuos (resto de columnas de la figura \ref{filters}.

\begin{figure}
    \centering
    \caption{Aplicación de diferentes filtros a la imagen de la figura \ref{seven}}
  \label{filters}
  \includegraphics{filters}
\end{figure}

Lo interesante de este método es que hemos conseguido resaltar características
del objeto representado en la imagen usando solo operaciones matriciales.

Las matrices de convolución pueden ser de mayor tamaño, permitiendo capturar características más complejas. La matriz de 3$\times$3 es la menor matriz que permite definir en su totalidad el concepto de espacio, pudiendo extraer características espaciales en dos dimensiones.

A la hora de trabajar con imágenes en color es necesario aplicar cada filtro a
cada capa por separado, permitiendo de esta manera detectar diferentes
características de la imagen que ocurran solo en uno de los colores.

Para analizar cómo afectan diferentes filtros a una imagen, en la página \parencite{visualizer_convolution} se pueden probar ejemplos con filtros personalizados, haciendo el concepto mucho más sencillo de comprender.

\section{Redes neuronales convolucionales}
\label{sec:conv-net}

Hemos explorado la idea de que determinados filtros son capaces de extraer información localizada sobre características de la imagen. En el ejemplo del apartado anterior, dada una imagen podíamos saber si había bordes superiores y dónde se podían encontrar. Esto puede ser de gran utilidad en el campo de reconocimiento de imágenes, ya que podemos usar esa información localizada para categorizar o aplicar otro tipo de técnicas en esas áreas señaladas. El problema radica en encontrar los mejores filtros para que extaigan las características más relevantes de una imagen.

Analizando cómo funcionan los filtros convolucionales vemos su parecido con las redes neuronales. Al igual que estas, los filtros se pueden entender como funciones que al aplicarse a los datos de entrada producen unos datos de salida que serán más o menos relevantes para el objetivo buscado. El entrenamiento de una red neuronal va modificando los pesos de las diferentes capas hasta que produce una salida relevante para cada ejemplo del conjunto de entrenamiento. Si entendemos los pesos como matrices convolucionales, podemos hacer que sea la propia red la que busque el mejor filtro para nuestro problema de clasificación. De hecho, ya que las redes neuronales son capaces de componer diferentes funciones en diferentes capas de la red para aprender funciones no lineales, podemos aplicar la misma idea a las redes con filtros: componer diferentes filtros para poder extraer características más complejas.

En esta idea se basan las redes convolucionales que trabajan con imágenes. Cada capa de la red constará de varios filtros que se aplicarán a las imágenes que reciba, proporcionando los resultados a la siguiente capa. Ya que lo que importa es la composición de filtros, cada capa deberá entrenar varios filtros al mismo tiempo, permitiendo así aumentar la combinatoria final.

De esta manera, los pesos de cada capa vendrían dados en una matriz tridimensional, que se puede entender como $d$ (profundidad) filtros de dimensión  $w \times h$ (anchura y altura), como se indica en la figura \ref{cnn_basic}.

\begin{figure}
    \centering
    \caption{\textit{Ejemplo de dos representaciones de la misma red convolucional. Abajo el modelo resumido con cajas.}}
  \label{cnn_basic}
  \includegraphics[width=.7\textwidth]{cnn}
\end{figure}


\subsection{Estructura de una capa convolucional}

El concepto de capa en una red convolucional incluye una agrupación de diferentes capas que efectúan diferentes operaciones. Como en las redes neuronales clásicas, la capa precisará de un tratamiento de las entradas con los pesos (en este caso los filtros convolucionales) y una función de activación.

\subsubsection{Capa convolucional - CONV \textit{(Convolutional layer)}}

Las capas convolucionales son las que hemos visto hasta ahora. Tendrán como pesos $n$ filtros convolucionales (todos del mismo tamaño) y producirán las $n$ imágenes resultantes de aplicar estos filtros a la imagen de entrada. Por ejemplo, de una imagen de tamaño $32\times 32$ proporcionada a una capa convolucional de 8 filtros se obtendrá una salida de tamaño $32 \times 32 \times 8$, o lo que es lo mismo, 8 imágenes $32 \times 32$.

\subsubsection{Capa de activación - RELU \textit{(Rectifier Linear layer)}}
\label{sec:relu}

Al igual que en las redes clásicas es necesario tratar la salida de la aplicación de los pesos sobre las entradas con una función de activación. 

La manera habitual de modelizar la salida de una neurona en las RNAs es a
través de $f(x) = tanh(x)$ o $f(x) = (1 + e^{-x})^{-1}$ (función sigmoide). A
la hora de entrenar la red con descenso del gradiente, estas funciones son
mucho más lentas que otra función que también evita la linealidad: $f(x) =
max(0, x)$, llamada ReLU (\textit{Rectifier Linear}). Las redes neuronales
convolucionales entrenan varias veces más rápido usando ReLU  que las
equivalentes usando la función $tanh$ (ver figura \ref{relu-vs-tanh}).

\begin{figure}
    \centering
    \caption{Evolución de un entrenamiento para una red convolucional de cuatro capas usando ReLUs (línea sólida) vs usando tanh (línea discontínua) \parencite{krizhevsky2012imagenet}}
  \label{relu-vs-tanh}
  \includegraphics[width=.6\textwidth]{relu-vs-tanh}
\end{figure}

\subsubsection{Capa de muestreo - POOL \textit{(Pooling layer)}}

Al usar convoluciones en una imagen, la información del entorno de cada punto
queda difuminada y redundante. Gracias a esto se puede reducir el tamaño del
problema mediante muestreo. Las capas de muestreo (\textit{pooling layers})
resumen las salidas del entorno de cada grupo de neuronas. Un ejemplo de
función de muestreo sería elegir el valor máximo de cada cuadrado de 4 píxeles
(figura \ref{maxpool}).

Si la salida de una capa CONV + RELU es $32 \times 32 \times 8$, al aplicar la capa de muestreo la salida se convertirá en $16 \times 16 \times 8$. Al eliminar el 75\% de las activaciones se reducen la cantidad de parámetros y el tiempo de computación, y además ayuda a reducir el sobreajuste.

\begin{figure}
    \centering
    \caption{\textit{Max-pooling sobre una imagen de $4\times4$}}
  \label{maxpool}
  \includegraphics[width=.6\textwidth]{maxpool}
\end{figure}

\subsubsection{Capa densa - FC \textit{(Fully connected layer)}}

Esta capa es una capa clásica de red neuronal. Su función es calcular las probabilidades de clasificación dadas las imágenes tratadas. Cada neurona de esta capa estará conectada a cada una de las activaciones de la capa anterior, produciendo una salida por cada clase a clasificar.

Esta capa suele usarse al final de la arquitectura, cuando se han producido varios ciclos de capas convolucionales (CONV + RELU + POOL). Sin embargo, también es común ver arquitecturas con varias capas FC conectadas al final, ampliando la flexibilidad de clasificación de la red en base a características extraidas.

\subsection{Arquitectura}
\label{sec:conv-net-arch}

\begin{figure}
    \centering
    \caption{Ejemplo de arquitectura de una red convolucional para clasificación, \parencite{clarifai}}
\label{conv-arch}
  \includegraphics{conv-arch}
\end{figure}

Un esquema simplificado de un ejemplo de uso de las capas mencionadas se puede encontrar en la figura \ref{conv-arch}. La idea es, mediante capas CONV + RELU + POOL, transformar la imagen en una multitud de representaciones de conceptos cada vez más abstractos. Una vez se alcancen dichos conceptos, usar capas FC para modelizar la salida de la red.

Como se verá en la solución presentada para este proyecto, en el capítulo \ref{cap:soluciones}, usar esta arquitectura permite apoyarse en determinadas estrategias para mejorar la eficacia del modelo predictivo.
