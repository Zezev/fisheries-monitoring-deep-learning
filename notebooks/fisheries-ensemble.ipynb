{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from random import randint\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/fishes/'\n",
    "full_path = os.getcwd() + '/' + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VERSION = 'sgd_002'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do list:\n",
    "\n",
    "1. Create validation set and sample\n",
    "2. Move to separate dirs for each set\n",
    "3. Finetune and train\n",
    "4. Submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3214 images belonging to 8 classes.\n",
      "Found 563 images belonging to 8 classes.\n",
      "Found 3214 images belonging to 8 classes.\n",
      "Found 563 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trn = get_data(path + 'train')\n",
    "#val = get_data(path + 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test = get_data(path+'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_array(path+'results/trn.dat', trn)\n",
    "#save_array(path+'results/val.dat', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_array(path+'results/test.dat', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn = load_array(path + 'results/trn.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = load_array(path + 'results/val.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = load_array(path + 'results/test.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precompute convolutional output\n",
    "\n",
    "We pre-compute the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers, fc_layers = split_at(model, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conv_feat = conv_model.predict(trn)\n",
    "#conv_val_feat = conv_model.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conv_test_feat = conv_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_array(path + 'results/conv_val_feat{}.dat'.format(VERSION), conv_val_feat)\n",
    "#save_array(path + 'results/conv_feat{}.dat'.format(VERSION), conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_array(path + 'results/conv_test_feat{}.dat'.format(VERSION), conv_test_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load precomputed conv. output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563, 512, 14, 14)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p/4),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(8, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.6  # dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(SGD(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3214 samples, validate on 563 samples\n",
      "Epoch 1/3\n",
      "3214/3214 [==============================] - 1s - loss: 1.5925 - acc: 0.4975 - val_loss: 0.6688 - val_acc: 0.8366\n",
      "Epoch 2/3\n",
      "3214/3214 [==============================] - 1s - loss: 0.6477 - acc: 0.8046 - val_loss: 0.3687 - val_acc: 0.9130\n",
      "Epoch 3/3\n",
      "3214/3214 [==============================] - 1s - loss: 0.3913 - acc: 0.8880 - val_loss: 0.2508 - val_acc: 0.9396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3387f1b950>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(\n",
    "    conv_feat,\n",
    "    trn_labels,\n",
    "    batch_size=batch_size,\n",
    "    nb_epoch=3,\n",
    "    validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3214 samples, validate on 563 samples\n",
      "Epoch 1/7\n",
      "3214/3214 [==============================] - 1s - loss: 0.2775 - acc: 0.9235 - val_loss: 0.2109 - val_acc: 0.9361\n",
      "Epoch 2/7\n",
      "3214/3214 [==============================] - 1s - loss: 0.2037 - acc: 0.9431 - val_loss: 0.1692 - val_acc: 0.9520\n",
      "Epoch 3/7\n",
      "3214/3214 [==============================] - 1s - loss: 0.1645 - acc: 0.9546 - val_loss: 0.1685 - val_acc: 0.9503\n",
      "Epoch 4/7\n",
      "3214/3214 [==============================] - 1s - loss: 0.1212 - acc: 0.9673 - val_loss: 0.1417 - val_acc: 0.9645\n",
      "Epoch 5/7\n",
      "3214/3214 [==============================] - 1s - loss: 0.1051 - acc: 0.9736 - val_loss: 0.1431 - val_acc: 0.9591\n",
      "Epoch 6/7\n",
      "3214/3214 [==============================] - 1s - loss: 0.0832 - acc: 0.9804 - val_loss: 0.1304 - val_acc: 0.9609\n",
      "Epoch 7/7\n",
      "3214/3214 [==============================] - 1s - loss: 0.0859 - acc: 0.9813 - val_loss: 0.1186 - val_acc: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3387f1a4d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=7, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/conv_512_6_{}.h5'.format(VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11859356453079817, 0.96802841918294846]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.evaluate(conv_val_feat, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(path+'models/conv_512_6_{}.h5'.format(VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = load_array(path+'results/test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_batches = get_batches(path + 'test', shuffle=False)\n",
    "preds = bn_model.predict(conv_test_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx):\n",
    "    return np.clip(arr, (1-mx)/7, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds, 0.85)\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path+'results/subm_bb_dp_{}.gz'.format(VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_06237.jpg</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_06893.jpg</td>\n",
       "      <td>0.628228</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.049763</td>\n",
       "      <td>0.175196</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.066550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02082.jpg</td>\n",
       "      <td>0.224164</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.709265</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.053195</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_06261.jpg</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_03628.jpg</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_06237.jpg  0.850000  0.021429  0.021429  0.021429  0.021429  0.021429   \n",
       "1  img_06893.jpg  0.628228  0.021429  0.021429  0.021429  0.049763  0.175196   \n",
       "2  img_02082.jpg  0.224164  0.021429  0.021429  0.021429  0.709265  0.021429   \n",
       "3  img_06261.jpg  0.850000  0.021429  0.021429  0.021429  0.021429  0.021429   \n",
       "4  img_03628.jpg  0.850000  0.021429  0.021429  0.021429  0.021429  0.021429   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.021429  0.021429  \n",
       "1  0.027436  0.066550  \n",
       "2  0.053195  0.021429  \n",
       "3  0.021429  0.021429  \n",
       "4  0.021429  0.021429  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'image', raw_test_filenames)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/fishes/results/subm_bb_dp_sgd_002.gz' target='_blank'>data/fishes/results/subm_bb_dp_sgd_002.gz</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/data/fishes/results/subm_bb_dp_sgd_002.gz"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
